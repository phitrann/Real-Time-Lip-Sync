{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is enabled: {'message': 'server enabled'}\n",
      "Generated digital human video: {'user_id': 'user123', 'request_id': 'req234', 'digital_human_mp4_path': '/space/hotel/phit/personal/rtlipsync/results/avatars/vid_output/req234.mp4'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Define the FastAPI server URL\n",
    "base_url = \"http://localhost:8010\"\n",
    "\n",
    "os.environ[\"no_proxy\"] = \"localhost,172.16.87.75\"\n",
    "\n",
    "# 1. Check Server Status\n",
    "response = requests.get(f\"{base_url}/digital_human/check\")\n",
    "if response.status_code == 200:\n",
    "    print(\"Server is enabled:\", response.json())\n",
    "\n",
    "# 2. Make a POST request to /digital_human/gen\n",
    "digital_human_data = {\n",
    "    \"user_id\": \"user123\",\n",
    "    \"request_id\": \"req123\",\n",
    "    \"streamer_id\": \"1\",\n",
    "    \"tts_path\": \"./data/audio/elon.wav\",\n",
    "    \"chunk_id\": 0\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{base_url}/digital_human/gen\", json=digital_human_data)\n",
    "if response.status_code == 200:\n",
    "    print(\"Generated digital human video:\", response.json())\n",
    "else:\n",
    "    print(\"Failed to generate digital human:\", response.text)\n",
    "\n",
    "# # 3. Make a POST request to /digital_human/preprocess\n",
    "# preprocess_data = {\n",
    "#     \"user_id\": \"user123\",\n",
    "#     \"request_id\": \"req123\",\n",
    "#     \"streamer_id\": \"streamer1\",\n",
    "#     \"video_path\": \"/path/to/video.mp4\"\n",
    "# }\n",
    "\n",
    "# response = requests.post(f\"{base_url}/digital_human/preprocess\", json=preprocess_data)\n",
    "# if response.status_code == 200:\n",
    "#     print(\"Preprocessing complete:\", response.json())\n",
    "# else:\n",
    "#     print(\"Failed to preprocess video:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is enabled: {'message': 'server enabled'}\n",
      "Generated digital human video: {'user_id': 'user123', 'request_id': 'req345', 'digital_human_mp4_path': '/space/hotel/phit/personal/rtlipsync/results/avatars/vid_output/req345.mp4'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Define the FastAPI server URL\n",
    "base_url = \"http://localhost:8000\"\n",
    "\n",
    "os.environ[\"no_proxy\"] = \"localhost,172.16.87.75\"\n",
    "\n",
    "# 1. Check Server Status\n",
    "response = requests.get(f\"{base_url}/digital_human/check\")\n",
    "if response.status_code == 200:\n",
    "    print(\"Server is enabled:\", response.json())\n",
    "\n",
    "# 2. Make a POST request to /digital_human/gen\n",
    "digital_human_data = {\n",
    "    \"user_id\": \"user123\",\n",
    "    \"request_id\": \"req345\",\n",
    "    \"streamer_id\": \"1\",\n",
    "    \"tts_path\": \"./data/audio/elon.wav\",\n",
    "    \"chunk_id\": 0\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{base_url}/digital_human/gen\", json=digital_human_data)\n",
    "if response.status_code == 200:\n",
    "    print(\"Generated digital human video:\", response.json())\n",
    "else:\n",
    "    print(\"Failed to generate digital human:\", response.text)\n",
    "\n",
    "# # 3. Make a POST request to /digital_human/preprocess\n",
    "# preprocess_data = {\n",
    "#     \"user_id\": \"user123\",\n",
    "#     \"request_id\": \"req123\",\n",
    "#     \"streamer_id\": \"streamer1\",\n",
    "#     \"video_path\": \"/path/to/video.mp4\"\n",
    "# }\n",
    "\n",
    "# response = requests.post(f\"{base_url}/digital_human/preprocess\", json=preprocess_data)\n",
    "# if response.status_code == 200:\n",
    "#     print(\"Preprocessing complete:\", response.json())\n",
    "# else:\n",
    "#     print(\"Failed to preprocess video:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'code': 0, 'msg': 'ok'}\n"
     ]
    }
   ],
   "source": [
    "# !curl -x \"\" -X POST http://172.16.87.75:8010/humanaudio -F \"file=@data/video/elon.mp4\" -F \"sessionid=0\"\n",
    "\n",
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "async def upload_audio_file(session_id, file_path):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            audio_data = {'file': file}\n",
    "            payload = {'sessionid': str(session_id)}\n",
    "            form = aiohttp.FormData()\n",
    "            form.add_field('sessionid', str(session_id))\n",
    "            form.add_field('file', open(file_path, 'rb'), filename=file_path)\n",
    "            \n",
    "            async with session.post('http://localhost:8010/humanaudio', data=form) as response:\n",
    "                response_json = await response.json()\n",
    "                print(f\"Response: {response_json}\")\n",
    "\n",
    "def run_async_main(session_id, file_path):\n",
    "    try:\n",
    "        # Check if there's an existing event loop and use it\n",
    "        loop = asyncio.get_running_loop()\n",
    "        loop.create_task(upload_audio_file(session_id, file_path))\n",
    "    except RuntimeError:\n",
    "        # If no running loop, use asyncio.run()\n",
    "        asyncio.run(upload_audio_file(session_id, file_path))\n",
    "\n",
    "# Example usage\n",
    "session_id = 0\n",
    "file_path = 'data/audio/elon.wav'\n",
    "run_async_main(session_id, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import aiohttp\n",
    "import pyaudio\n",
    "import av\n",
    "from aiortc import RTCPeerConnection, RTCSessionDescription\n",
    "from aiortc.contrib.media import MediaPlayer\n",
    "import websockets\n",
    "import os\n",
    "\n",
    "pc = None\n",
    "\n",
    "async def send_offer(session, url):\n",
    "    global pc\n",
    "\n",
    "    pc = RTCPeerConnection()\n",
    "\n",
    "    # Add transceivers for video (recvonly) and audio (sendonly)\n",
    "    pc.addTransceiver('video', direction='recvonly')\n",
    "    pc.addTransceiver('audio', direction='sendonly')\n",
    "\n",
    "    # Create an offer and set the local description\n",
    "    offer = await pc.createOffer()\n",
    "    await pc.setLocalDescription(offer)\n",
    "\n",
    "    # Wait for ICE gathering to complete\n",
    "    await ice_gathering_complete(pc)\n",
    "\n",
    "    # Send the offer to the /offer endpoint on the server\n",
    "    async with session.post(f'{url}/offer', json={\n",
    "        'sdp': pc.localDescription.sdp,\n",
    "        'type': pc.localDescription.type\n",
    "    }) as response:\n",
    "        answer = await response.json()\n",
    "\n",
    "    # Set the remote description\n",
    "    sessionid = answer.get('sessionid')\n",
    "    print(f\"Session ID: {sessionid}\")\n",
    "    await pc.setRemoteDescription(RTCSessionDescription(sdp=answer['sdp'], type=answer['type']))\n",
    "\n",
    "    return sessionid, pc\n",
    "\n",
    "async def ice_gathering_complete(pc):\n",
    "    if pc.iceGatheringState == 'complete':\n",
    "        return\n",
    "\n",
    "    ice_complete = asyncio.Future()\n",
    "\n",
    "    @pc.on('icegatheringstatechange')\n",
    "    def check_ice():\n",
    "        if pc.iceGatheringState == 'complete':\n",
    "            ice_complete.set_result(True)\n",
    "\n",
    "    await ice_complete\n",
    "\n",
    "async def send_audio_data(websocket, sessionid, audio_data):\n",
    "    # Encode audio data to base64 string to ensure safe transmission\n",
    "    await websocket.send(json.dumps({\n",
    "        'type': 'audio',\n",
    "        'sessionid': sessionid,\n",
    "        'data': audio_data.decode('latin-1')  # Convert bytes to string\n",
    "    }))\n",
    "\n",
    "async def receive_video(track):\n",
    "    # Optionally, process the received video frames\n",
    "    while True:\n",
    "        frame = await track.recv()\n",
    "        # Process the video frame (e.g., display, save, etc.)\n",
    "        # For this example, we will just print a message\n",
    "        print(\"Received video frame\")\n",
    "\n",
    "async def main(audio_file_path=\"data/audio/elon.wav\"):\n",
    "    url = \"http://localhost:8010\"  # Replace with your server's address\n",
    "    ws_url = \"ws://localhost:8010/ws\"  # WebSocket URL\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        # Establish WebRTC connection\n",
    "        sessionid, pc = await send_offer(session, url)\n",
    "\n",
    "        # Set up WebSocket connection\n",
    "        async with websockets.connect(ws_url) as websocket:\n",
    "            # Send session ID to associate with server-side processing\n",
    "            await websocket.send(json.dumps({'type': 'session', 'sessionid': sessionid}))\n",
    "\n",
    "            # Set up audio source (microphone or pre-recorded file)\n",
    "            audio_source = None\n",
    "            # p = pyaudio.PyAudio()\n",
    "            # try:\n",
    "            #     # Try to open the microphone for audio input\n",
    "            #     stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=1024)\n",
    "            #     audio_source = 'microphone'\n",
    "            #     print(\"Using microphone for audio input\")\n",
    "            # except OSError as e:\n",
    "            #     print(f\"Error opening microphone: {e}\")\n",
    "            #     # No microphone available, use a pre-recorded audio file\n",
    "            #     audio_source = 'file'\n",
    "            #     print(\"Using pre-recorded audio file for audio input\")\n",
    "            #     if not os.path.exists(audio_file_path):\n",
    "            #         print(f\"Audio file not found at {audio_file_path}\")\n",
    "            #         return\n",
    "            #     audio_player = MediaPlayer(audio_file_path)\n",
    "            #     audio_stream = audio_player.audio\n",
    "            \n",
    "            audio_source = 'file'\n",
    "            print(\"Using pre-recorded audio file for audio input\")\n",
    "            if not os.path.exists(audio_file_path):\n",
    "                print(f\"Audio file not found at {audio_file_path}\")\n",
    "                return\n",
    "            audio_player = MediaPlayer(audio_file_path)\n",
    "            audio_stream = audio_player.audio\n",
    "\n",
    "            # Start receiving video\n",
    "            @pc.on(\"track\")\n",
    "            async def on_track(track):\n",
    "                if track.kind == \"video\":\n",
    "                    print(\"Received video track\")\n",
    "                    await receive_video(track)\n",
    "\n",
    "            try:\n",
    "                if audio_source == 'microphone':\n",
    "                    while True:\n",
    "                        # Read audio data from microphone\n",
    "                        audio_data = stream.read(1024, exception_on_overflow=False)\n",
    "                        # Send audio data through WebSocket\n",
    "                        await send_audio_data(websocket, sessionid, audio_data)\n",
    "                elif audio_source == 'file':\n",
    "                    while True:\n",
    "                        # Read audio frame from the media player\n",
    "                        frame = await audio_stream.recv()\n",
    "                        # Get audio data as bytes\n",
    "                        audio_data = bytes(frame.planes[0])\n",
    "                        # Send audio data through WebSocket\n",
    "                        await send_audio_data(websocket, sessionid, audio_data)\n",
    "                        # Sleep to match the audio frame duration\n",
    "                        await asyncio.sleep(frame.time_base * frame.samples)\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"Stopping...\")\n",
    "            finally:\n",
    "                # # Clean up\n",
    "                # if audio_source == 'microphone':\n",
    "                #     stream.stop_stream()\n",
    "                #     stream.close()\n",
    "                #     p.terminate()\n",
    "                # elif audio_source == 'file':\n",
    "                #     audio_player.close()\n",
    "                await pc.close()\n",
    "                await websocket.close()\n",
    "\n",
    "def run_async_main():\n",
    "    asyncio.run(main())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_async_main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

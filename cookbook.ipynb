{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lip-synced video saved as output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# os.environ[\"no_proxy\"] = \"localhost,172.16.87.75\"\n",
    "\n",
    "# # API endpoint\n",
    "# url = \"http://localhost:8000/lip_sync\"\n",
    "\n",
    "# # Prepare the data\n",
    "# try:\n",
    "#     video_file = open('data/video/sun.mp4', 'rb')\n",
    "#     audio_file = open('data/audio/sun.wav', 'rb')\n",
    "# except FileNotFoundError as e:\n",
    "#     print(f\"Error: {e}\")\n",
    "#     exit(1)\n",
    "\n",
    "# files = {\n",
    "#     'video': ('sun.mp4', video_file, 'video/mp4'),\n",
    "#     'audio': ('sun.wav', audio_file, 'audio/wav'),\n",
    "# }\n",
    "\n",
    "# data = {\n",
    "#     'avatar_id': 'avator_1',\n",
    "#     'fps': 25,\n",
    "#     'batch_size': 4\n",
    "# }\n",
    "\n",
    "# try:\n",
    "#     # Send the POST request\n",
    "#     response = requests.post(url, files=files, data=data, stream=True)\n",
    "\n",
    "#     # Output video path\n",
    "#     output_video_path = 'output_video.mp4'\n",
    "\n",
    "#     # Check if the request was successful\n",
    "#     if response.status_code == 200:\n",
    "#         # Create a video writer (adjust codec and parameters as needed)\n",
    "#         fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Use 'XVID' for .avi\n",
    "#         out = None \n",
    "\n",
    "#         # Create a bytes buffer for the image data\n",
    "#         bytes_buffer = bytes()\n",
    "\n",
    "#         for chunk in response.iter_content(chunk_size=1024):\n",
    "#             if chunk:\n",
    "#                 bytes_buffer += chunk\n",
    "#                 a = bytes_buffer.find(b'\\xff\\xd8')  # JPEG start\n",
    "#                 b = bytes_buffer.find(b'\\xff\\xd9')  # JPEG end\n",
    "#                 if a != -1 and b != -1:\n",
    "#                     jpg = bytes_buffer[a:b+2]\n",
    "#                     bytes_buffer = bytes_buffer[b+2:]\n",
    "#                     frame = cv2.imdecode(np.frombuffer(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "                    \n",
    "#                     # Initialize the video writer with frame size\n",
    "#                     if out is None and frame is not None:\n",
    "#                         height, width, _ = frame.shape\n",
    "#                         out = cv2.VideoWriter(output_video_path, fourcc, data['fps'], (width, height))\n",
    "\n",
    "#                     # Write the frame to the video writer\n",
    "#                     if out is not None:\n",
    "#                         out.write(frame)\n",
    "\n",
    "#         # Release the video writer\n",
    "#         if out is not None:\n",
    "#             out.release()\n",
    "\n",
    "#         print(f\"Lip-synced video saved as {output_video_path}\")\n",
    "#     else:\n",
    "#         print(f\"Error: {response.status_code}\")\n",
    "#         print(response.text)\n",
    "# finally:\n",
    "#     # Close the files\n",
    "#     video_file.close()\n",
    "#     audio_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is enabled: {'message': 'server enabled'}\n",
      "Generated digital human video: {'user_id': 'user123', 'request_id': 'req234', 'digital_human_mp4_path': '/space/hotel/phit/personal/rtlipsync/results/avatars/vid_output/req234.mp4'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Define the FastAPI server URL\n",
    "base_url = \"http://localhost:8000\"\n",
    "\n",
    "os.environ[\"no_proxy\"] = \"localhost,172.16.87.75\"\n",
    "\n",
    "# 1. Check Server Status\n",
    "response = requests.get(f\"{base_url}/digital_human/check\")\n",
    "if response.status_code == 200:\n",
    "    print(\"Server is enabled:\", response.json())\n",
    "\n",
    "# 2. Make a POST request to /digital_human/gen\n",
    "digital_human_data = {\n",
    "    \"user_id\": \"user123\",\n",
    "    \"request_id\": \"req123\",\n",
    "    \"streamer_id\": \"1\",\n",
    "    \"tts_path\": \"./data/audio/elon.wav\",\n",
    "    \"chunk_id\": 0\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{base_url}/digital_human/gen\", json=digital_human_data)\n",
    "if response.status_code == 200:\n",
    "    print(\"Generated digital human video:\", response.json())\n",
    "else:\n",
    "    print(\"Failed to generate digital human:\", response.text)\n",
    "\n",
    "# # 3. Make a POST request to /digital_human/preprocess\n",
    "# preprocess_data = {\n",
    "#     \"user_id\": \"user123\",\n",
    "#     \"request_id\": \"req123\",\n",
    "#     \"streamer_id\": \"streamer1\",\n",
    "#     \"video_path\": \"/path/to/video.mp4\"\n",
    "# }\n",
    "\n",
    "# response = requests.post(f\"{base_url}/digital_human/preprocess\", json=preprocess_data)\n",
    "# if response.status_code == 200:\n",
    "#     print(\"Preprocessing complete:\", response.json())\n",
    "# else:\n",
    "#     print(\"Failed to preprocess video:\", response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 11m29s to solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is enabled: {'message': 'server enabled'}\n",
      "Generated digital human video: {'user_id': 'user123', 'request_id': 'req345', 'digital_human_mp4_path': '/space/hotel/phit/personal/rtlipsync/results/avatars/vid_output/req345.mp4'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Define the FastAPI server URL\n",
    "base_url = \"http://localhost:8000\"\n",
    "\n",
    "os.environ[\"no_proxy\"] = \"localhost,172.16.87.75\"\n",
    "\n",
    "# 1. Check Server Status\n",
    "response = requests.get(f\"{base_url}/digital_human/check\")\n",
    "if response.status_code == 200:\n",
    "    print(\"Server is enabled:\", response.json())\n",
    "\n",
    "# 2. Make a POST request to /digital_human/gen\n",
    "digital_human_data = {\n",
    "    \"user_id\": \"user123\",\n",
    "    \"request_id\": \"req345\",\n",
    "    \"streamer_id\": \"1\",\n",
    "    \"tts_path\": \"./data/audio/elon.wav\",\n",
    "    \"chunk_id\": 0\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{base_url}/digital_human/gen\", json=digital_human_data)\n",
    "if response.status_code == 200:\n",
    "    print(\"Generated digital human video:\", response.json())\n",
    "else:\n",
    "    print(\"Failed to generate digital human:\", response.text)\n",
    "\n",
    "# # 3. Make a POST request to /digital_human/preprocess\n",
    "# preprocess_data = {\n",
    "#     \"user_id\": \"user123\",\n",
    "#     \"request_id\": \"req123\",\n",
    "#     \"streamer_id\": \"streamer1\",\n",
    "#     \"video_path\": \"/path/to/video.mp4\"\n",
    "# }\n",
    "\n",
    "# response = requests.post(f\"{base_url}/digital_human/preprocess\", json=preprocess_data)\n",
    "# if response.status_code == 200:\n",
    "#     print(\"Preprocessing complete:\", response.json())\n",
    "# else:\n",
    "#     print(\"Failed to preprocess video:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"code\":-1,\"msg\":\"err\",\"data\":\"list index out of range\"}\n"
     ]
    }
   ],
   "source": [
    "# !curl -x \"\" -X POST http://172.16.87.75:8010/humanaudio -F \"file=@data/video/elon.mp4\" -F \"sessionid=0\"\n",
    "\n",
    "import os\n",
    "import httpx\n",
    "\n",
    "os.environ[\"no_proxy\"] = \"localhost,172.16.87.75,127.0.0.1\"\n",
    "\n",
    "url = \"http://172.16.87.75:8010/humanaudio\"\n",
    "files = {\n",
    "    'file': open('/space/hotel/phit/personal/rtlipsync/data/audio/elon.wav', 'rb'),\n",
    "    'sessionid': (None, '0')\n",
    "}\n",
    "\n",
    "response = httpx.post(url, files=files)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 103\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[38;5;28;01mawait\u001b[39;00m video_task\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 103\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/space/hotel/phit/miniconda3/envs/speech/lib/python3.10/asyncio/runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import websockets\n",
    "import json\n",
    "import aiohttp\n",
    "import pyaudio\n",
    "import wave\n",
    "import av\n",
    "from aiortc import RTCPeerConnection, RTCSessionDescription, VideoStreamTrack\n",
    "from aiortc.contrib.media import MediaPlayer\n",
    "from aiortc import MediaStreamTrack\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"no_proxy\"] = \"localhost,172.16.87.75,127.0.0.1\"\n",
    "\n",
    "\n",
    "class AudioStreamTrack(MediaStreamTrack):\n",
    "    kind = \"audio\"\n",
    "\n",
    "    def __init__(self, track):\n",
    "        super().__init__()\n",
    "        self.track = track\n",
    "\n",
    "    async def recv(self):\n",
    "        frame = await self.track.recv()\n",
    "        return frame\n",
    "\n",
    "async def send_offer(session, url):\n",
    "    pc = RTCPeerConnection()\n",
    "    \n",
    "    # Add audio track\n",
    "    audio_track = AudioStreamTrack(MediaPlayer('data/audio/elon.wav').audio)\n",
    "    pc.addTrack(audio_track)\n",
    "\n",
    "    # Create and set local description\n",
    "    await pc.setLocalDescription(await pc.createOffer())\n",
    "\n",
    "    # Send the offer to the server\n",
    "    async with session.post(f'{url}/offer', json={\n",
    "        'sdp': pc.localDescription.sdp,\n",
    "        'type': pc.localDescription.type\n",
    "    }) as response:\n",
    "        answer = await response.json()\n",
    "        await pc.setRemoteDescription(RTCSessionDescription(sdp=answer['sdp'], type=answer['type']))\n",
    "        return answer['sessionid'], pc\n",
    "\n",
    "async def send_audio_data(websocket, sessionid, audio_data):\n",
    "    await websocket.send(json.dumps({\n",
    "        'type': 'audio',\n",
    "        'sessionid': sessionid,\n",
    "        'data': audio_data.tobytes().decode('latin-1')  # Convert bytes to string\n",
    "    }))\n",
    "\n",
    "async def receive_video(pc, output_file):\n",
    "    # Set up a video recorder\n",
    "    recorder = av.open(output_file, 'w')\n",
    "    video_stream = recorder.add_stream('h264', rate=30)\n",
    "    \n",
    "    @pc.on(\"track\")\n",
    "    async def on_track(track):\n",
    "        if track.kind == \"video\":\n",
    "            while True:\n",
    "                frame = await track.recv()\n",
    "                # Encode and write the frame\n",
    "                packet = video_stream.encode(frame)\n",
    "                if packet:\n",
    "                    recorder.mux(packet)\n",
    "\n",
    "async def main():\n",
    "    url = \"http://localhost:8010\"  # Replace with your server's address\n",
    "    ws_url = \"ws://localhost:8010/ws\"  # WebSocket URL\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        # Establish WebRTC connection\n",
    "        sessionid, pc = await send_offer(session, url)\n",
    "\n",
    "        # Set up WebSocket connection\n",
    "        async with websockets.connect(ws_url) as websocket:\n",
    "            # Set up PyAudio for microphone input\n",
    "            p = pyaudio.PyAudio()\n",
    "            stream = p.open(format=pyaudio.paInt16, channels=1, rate=44100, input=True, frames_per_buffer=1024)\n",
    "\n",
    "            # Start receiving video\n",
    "            video_task = asyncio.create_task(receive_video(pc, 'output_video.mp4'))\n",
    "\n",
    "            try:\n",
    "                while True:\n",
    "                    # Read audio data from microphone\n",
    "                    audio_data = stream.read(1024)\n",
    "                    # Send audio data through WebSocket\n",
    "                    await send_audio_data(websocket, sessionid, audio_data)\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"Stopping...\")\n",
    "            finally:\n",
    "                # Clean up\n",
    "                stream.stop_stream()\n",
    "                stream.close()\n",
    "                p.terminate()\n",
    "                await pc.close()\n",
    "                await video_task\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
